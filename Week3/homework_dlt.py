# -*- coding: utf-8 -*-
"""Homework: data talks club  - data extraction and ingestion.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Te-AT0lfh0GpChg1Rbd0ByEKOHYtWXfm

# **Homework**: Data talks club data engineering zoomcamp Data loading workshop

Hello folks, let's practice what we learned - Loading data with the best practices of data engineering.

Here are the exercises we will do

# 1. Use a generator

Remember the concept of generator? Let's practice using them to futher our understanding of how they work.

Let's define a generator and then run it as practice.

**Answer the following questions:**

- **Question 1: What is the sum of the outputs of the generator for limit = 5?**
- **Question 2: What is the 13th number yielded**

I suggest practicing these questions without GPT as the purpose is to further your learning.
"""

# Question1:
def square_root_generator(limit):
    n = 1
    add_sqrt=[]
    while n <= limit:
        yield n ** 0.5
        add_sqrt.append(n ** 0.5)
        n += 1

#Example usage:
limit = 5
add_sqrt=0
generator = square_root_generator(limit)
for sqrt_value in generator:
    add_sqrt = add_sqrt + sqrt_value
    print(sqrt_value)
print('The sum of the square roots is:', add_sqrt)

# Question2:
limit = 13
add_sqrt=0
generator = square_root_generator(limit)
for sqrt_value in generator:
    add_sqrt = add_sqrt + sqrt_value
    print(sqrt_value)
print('The sum of the square roots is:', add_sqrt)


"""# 2. Append a generator to a table with existing data


Below you have 2 generators. You will be tasked to load them to duckdb and answer some questions from the data

1. Load the first generator and calculate the sum of ages of all people. Make sure to only load it once.
2. Append the second generator to the same table as the first.
3. **After correctly appending the data, calculate the sum of all ages of people.**



"""

def people_1():
    for i in range(1, 6):
        yield {"ID": i, "Name": f"Person_{i}", "Age": 25 + i, "City": "City_A"}

for person in people_1():
    print(person)

def people_2():
    for i in range(3, 9):
        yield {"ID": i, "Name": f"Person_{i}", "Age": 30 + i, "City": "City_B", "Occupation": f"Job_{i}"}

for person in people_2():
    print(person)

# Commented out IPython magic to ensure Python compatibility.
# #Install the dependencies
# %%capture
# import dlt
# !pip install dlt[duckdb]
# 
# # define the connection to load to.
# # We now use duckdb, but you can switch to Bigquery later
# generators_assignment_pipeline = dlt.pipeline(destination='duckdb', dataset_name='generators')
# 
# # we can load any generator to a table at the pipeline destnation as follows:
# info = generators_assignment_pipeline.run(people_1(),
# 										table_name="people_1",
# 										write_disposition="replace")
# 
# # the outcome metadata is returned by the load and we can inspect it by printing it.
# print(info)

print(info)

# show outcome

import duckdb

conn = duckdb.connect(f"{generators_assignment_pipeline.pipeline_name}.duckdb")

# let's see the tables
conn.sql(f"SET search_path = '{generators_assignment_pipeline.dataset_name}'")
print('Loaded tables: ')
display(conn.sql("show tables"))

# and the data

print("\n\n\n people_1 table below:")

rides = conn.sql("SELECT * FROM people_1").df()
display(rides)

# As you can see, the same data was loaded in both cases.

#Question1: Sum of the age of all the people in generator 1
rides = conn.sql("SELECT SUM(age) FROM people_1").df()
display(rides)

# Append the second generator to the same table as the first.

# Loading the second generator as people 2.
info = generators_assignment_pipeline.run(people_2(),
										table_name="people_2",
										write_disposition="replace")
# the outcome metadata is returned by the load and we can inspect it by printing it.
print(info)

# Observing the tables
print("\n\n\n people_1 table below:")

rides = conn.sql("SELECT * FROM people_1").df()
display(rides)

print("\n\n\n people_2 table below:")

rides = conn.sql("SELECT * FROM people_2").df()
display(rides)

# Append the second generator to the same table as the first.
# Loading the second generator as people 2.
info = generators_assignment_pipeline.run(people_2(),
										table_name="people_1",
										write_disposition="append")

# Observing the tables
print("\n\n\n people_1 table below:")

rides = conn.sql("SELECT * FROM people_1").df()
display(rides)

# Question2: Calculate the sum of all ages of people in the appended table.
rides2 = conn.sql("SELECT SUM(age) FROM people_1").df()
display(rides2)

"""# 3. Merge a generator

Re-use the generators from Exercise 2.

A table's primary key needs to be created from the start, so load your data to a new table with primary key ID.

Load your first generator first, and then load the second one with merge. Since they have overlapping IDs, some of the records from the first load should be replaced by the ones from the second load.

After loading, you should have a total of 8 records, and ID 3 should have age 33.

Question: **Calculate the sum of ages of all the people loaded as described above.**

"""

# Loading people_2 generator to a merge table
info = generators_assignment_pipeline.run(people_1(),
										table_name="merge_table",
										write_disposition="replace")
# Observing the merge_table
print("\n\n\n merge_table:")

rides = conn.sql("SELECT * FROM merge_table").df()
display(rides)

# Merging table_2 to the merge_table using primary key Id '
info = generators_assignment_pipeline.run(people_2(),
										table_name="merge_table",
										write_disposition="merge",
                    primary_key='id')

# Observing the merge_table after merge operation
print("\n\n\n merge_table:")

rides = conn.sql("SELECT * FROM merge_table").df()
display(rides)

#Question: Calculate the sum of ages of all the people loaded as described above.

rides3 = conn.sql("SELECT SUM(age) FROM merge_table").df()
display(rides3)